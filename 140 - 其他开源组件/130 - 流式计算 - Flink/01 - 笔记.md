# 进度

- [ ] 基础篇：基本概念，quick start，基本运行架构
- [ ] 核心篇：基本 API，时间语义，窗口
- [ ] 高级篇：处理函数，状态编程，容错机制
- [ ] SQL 篇：sql-client，查询 sql，connector，catalog，module

学习视频[来源](https://www.bilibili.com/video/BV1eg4y1V7AN/)

跳过部分

- P17-P21
- P25
- P27
- P32

# Flink 概述


是什么：Flink 是一套流式计算框架

- 批处理和流处理用同一套代码或 SQL：不需要分别为批处理和流处理各单独维护一套代码或 SQL
- 性能高：吞吐大，低时延（比较模糊）
- 架构：支持分布式，支持水平扩展，支持存储超大规模的中间计算结果，支持增量检查点机制（不知道这个是啥意思）
- 生态：能集成 Yarn，K8s，或独立运行
- 高容错：自动重试，一致性检查点，保证状态一致性（课上说，大白话意思就是，计算一条数据时出错并重试时，是从头计算还是从出错的那一步开始重试）

## Flink 里一些简单名词和概念的介绍

一些名词的简单解释

- Flink 是事件驱动此应用：Flink 是被动型程序，有数据来就处理，没数据来就歇着
- Flink 的输入和输出源
- 有界流和无界流：无界流好理解，不解释。case：来自 MQ 的数据；有界流相当于知道会来多少数据，全都来后再处理，所以可以等全都来后先排个序啊再处理，case：读取文件里的数据
- 有状态的流处理：如果是无状态的流处理，相当于 Flink 只提供函数和局部变量，如果想记录中间结果就需要引入 MySQL 之类的数据存储组件
- 结果准确性：如果没有明确的事件时间定义，那么接收数据的时间是今天 23:59:59，计算完数据的时间是 00:00:01，那这条数据算是今天计算的还是明天计算的（暂时不知道区分这个有什么意义）
		- 时间时间：数据产生的时间
	- 处理时间：开始处理数据的时间
- 精准一次（exactly-one）：如果处理 MQ 里的消息，做到每条消息只有效消费一次（不丢失消息，不重复计算消息），如果不保证精准一次，就会出现不一致。想要保证数据一直就需要手动签收消息，保证幂等等手段实现 exactly-one。如果用的是 Spark Streaming，exactly-one 需要自行手动写代码实现手动签收，保证幂等等，但 Flink 直接提供了这个功能
- Flink 分层 API：虽然提供了分层 API，上层 AIP 是对下层 API 的封装。需要掌握 SQL API 和 Stream API 即可

> [!tip] Spark 和 Flink 的区别 
> - Spark / Spark Streaming 以批处理为根本，Flink 是真正实现了流处理




## quick start

1. 创建 idea 项目，导入 flink-1.17.0 依赖（flnk-stream-java, flink-clients）
2. 用 data set api 实现 word count

quick start 不需要搭建 flink server，直接在 demo 里写代码即可运行


> [!tip] 用 链式编程时，flink 的 api 用 lambda 有时候会报错，因为 lambda 的类型推断提供不了足够的信息，可能会导致运行报错。有两个方式解决问题
> - 用匿名内部类方式写
> - 链式调用 reture，显示传入类型对象
> ![[../../020 - 附件文件夹/Pasted image 20230623204500.png]]

> [!tip] IDEA 和 Maven 使用小技巧
> 生产环境下像 flink server 有的 flink-clients、flink-stream-java 这种已经有的依赖，在 Java 客户端项目的 pom 文件里设置成 scope provided 即可。他表示打包时不打进来。但这样在 IDEA 运行程序会导致找不到类，就需要在 IDEA 的 application configuration 里勾选运行时把 provided 也打包进来。至于为啥生产环境不把这些包打进来，我还不知道为啥

## flink server 作业提交方式

作业：写了一个方法就相当于定义了一个 job

**web-ui 上提交**

在 flink-web-ui 里提交 job 步骤如下

1. 项目打 jar 包
2. 在 flink-web-ui 上传 jar 包，并选择 job 所属的类，方法，方法入参，并行度等
3. 点击提交按钮

**命令行提交**

用的也不少

## 部署模式

pre-job 模式有被弃用趋势，被 application job 模式取代

# Flink 运行时架构

- jobmanager 和 jobmaster 的关系：前者是”老大“，是一个进程，后者是一个线程，前者可以只有多个后者的线程
- jobmaster 和 job 的关系：客户端提交了一个 job 后 jobmanager 就会创建一个对应的 jobmaster 线程
- 算子：客户端创建了一个 word count 的  job，job 读到数据后，第一步用空格分割出多个单词，下一步是根据 word 分组，下一步是对分组结果进行 sum 计算，下一步是打印结果。每一步都是一个算子
- 算子链：一对一和重分区的区别。在并行算子里，如果算子的输出结果给另一个算子时需要发送到指定的 task manager 的算子就是重分区。比如 word count 里，“hello” 的数量只有 1 号 task manager 知道，那么分组算子就得把统计 “hello” 的数量结果发给 1号 task manager
- 怎么区分哪些是一对一和重分区：在 web-ui 里能看到 job 的流程图，如果线条上有 forward 表示连接的两个算子是一对一的关系，其它基本都是重分区的关系
- 逻辑流图和job流图的区别：逻辑流图就是 flink 根据客户端调用算子的顺序生成的图结构，job流图是基于逻辑流图的优化，比如把多个一对一的算子合并成一个


# Stream API

获取 StreamExecutionEnvironment 的方式主要有以下三种

- createLocal 获取本地环境
- createRemote 获取远程集群环境
- getEnv 自动获取环境