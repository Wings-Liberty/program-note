Flink 是流式计算框架，其功能和使用方式很简单

# 它是怎么计算数据的？

1. 指定数据的来源，从来源处不断获取一条条数据
2. 让数据进入提前绘制好的流程（就像画流程图一样，不过绘制的方式是调用 API）
3. 把数据发送到目的地（比如数据库，MQ 等地方）

# 它提供什么功能？

- 实时计算，提供流处理和批处理（流处理和批处理能复用同一套代码，而 Spark 就不能，后者需要维护两套代码）
- 支持处理有界流和无界流（可以先对有界流做排序之类的行为后再进行后续计算）
- 提供状态机制 -- 能保存自定义变量
- 事件驱动 -- 来数据才处理，没来数据就进行低消耗方式空转
- 支持搭建集群，且管理集群方式多样化 -- 能集成 Yarn，K8s，或独立运行
- 支持容灾 -- 宕机后重启时能从宕机前的状态继续运行
- 直接提供精准一次（exactly-one）功能


# 它和 Spark 的区别是什么？


| 功能     | Flink                  | Spark                                      |
| -------- | ---------------------- | ------------------------------------------ |
| 流批处理 |流处理为根本。支持流处理和批处理|批处理为根本，支持微批处理，不支持流处理|
| 状态机制 | 支持                   | 不支持                                     |
| 精准一次 | 支持，通过修改配置即可 | 不支持                                     |
| 时间语义 | 提供事件时间和处理时间 | 只提供处理时间                             |
| 窗口     | 支持                   | 支持，但不够灵活（窗口必须是批次的整数倍） | 


# 它的分层 API 是什么意思？

Flink 提供了供用户调用的 API，但有的 API 类似写 sql 语句，有的 API 类似通过实现接口方法来自定义处理数据的逻辑

Flink 根据其提供的目的和实现方式对这些 API 进行了分层

| API 名称            | 提供的目的                      | 实现方式                     |
| ------------------- | ------------------------------- | ---------------------------- |
| SQL                 | 像写 sql 语句一样的调用         | 封装了 Table API             |
| Table API           | 像操作数据库表一样的 API        | 封装了底层 API 和 Stream API |
| Stream API          | 提供更易用的 API                | 封装了底层 API               |
| 底层 API - 处理函数 | 提供最底层 API 用于实现任何功能 | 有状态流处理                 |

越顶层的 API 越易用，但是越不灵活

抄作业：只调用 Stream API 和 底层 API



# 名词解释

- 任务，子任务：任务就是 job，是定义信息。子任务是算子，千万认为处理一条数据就是执行了1个任务|
- 时间
	- 时间时间：数据产生的时间
	- 处理时间：开始处理数据的时间
- 输入源和输出源