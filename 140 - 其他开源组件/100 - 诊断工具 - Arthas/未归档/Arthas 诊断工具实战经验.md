
概要：熟悉使用  可能会很好地帮助快速定位程序运行时问题（不一定是线上的，开发，测试环境都可以）

场景描述：

2022.11.23 晚上 ~ 2022.24 早上，重庆信安项目 APP 检测任务冒烟自测

创建任务，调度任务一直失败，最终手动排查到如下错误

- getAppTask 方法对比两个对象的两个字段是否一致时，a 对象的 int 和 b 对象的 string 字段进行了对比，导致 if 语句总是返回 false
（不需要 arthas）
- xxl-job 定时任务执行一个查询 sql 时，一个 mapper.xml 里的 resultMap 写错了，一个 Java 类的属性名 name 写为了 namea
（不需要 arthas）
- 使用 Func.toInt 把 double 转 int 时返回结果总是 -1（错误原因是，方法会把入参转为 string 再调 Integer.valueOf 如果转换抛异常或入参为空，返回默认值 -1）
（不需要 arthas）
- 工具类和调用工具方法的地方都没有对入参判空，导致工具类方法返回 null，调用工具类处出现空指针异常（getAppTask）
（需要 arthas 查看方法入参，而不是手动添加 log.info）
- 发现一个 appEngineTaskId 为空时，去做了一个查询查这个 id，然后就拿 appEngineTaskId 做一些入库，查询等 sql。问题是 appEngineTaskId 为空时，去做了一个查询查这个 id，但最终没有把查到的 id 赋值给 appEngineTaskId 就去用 appEngineTaskId 了，且调用处和被调用的方法都没有判空，导致异常
（不需要 arthas）
- 调用一个查询任务进度 API 时，API 返回 0 表示成功，并携带数据，但调用方写为了如果返回结果为 0 就认为调用失败，方法直接返回 false，不再向下执行
（不需要 arthas）
- 上述若干个代码都是在 xxl-job 的任务调度方法里执行的，如果执行抛异常抛到最外层，整个调度方法会回滚，导致下次调度时重新执行，处理的数据还和上次一样，方法重新抛异常回滚，这个问题会一直重复
（）

在手动定位解决以上问题时，花费了大量的时间，从 23 号晚上 9 点 23 到 24 号早上 2 点，约 4 个半小时。排查过程共计 3 人参与，其中

- 1 人受到以上 bug （主要是第一个问题 getAppTask）影响导致自己的功能测试被阻塞，但本身不是造 bug 的主要原因，所以参与度不高
- 1 人排查 bug 能力不足，参与但没有快速定位到 bug
- 以上 7 个 bug 由我一个人发现的，所以实际排查过程实际上是 1 个人结果贡献度在 70%~80%+，其他人的结果贡献度不高

排查耗时的原因在于

- 依靠 Java 的 jar 程序日志文件输入 + linux 的 tail -f 指令 + vi 的关键字搜索效率比较低。因为日志内容多，多人操作也会导致排查者看到其他人的访问日志，有些日志比较长，一条日志可能就刷屏了
- 定位问题慢，只能依靠 log.info 方式模糊定位哪个接口，哪个方法调用有问题
- 依靠 log.info 定位，添加 log.info 语句或检查到问题原因并修改了少量代码时，需要重新打包，打包 + 上传到服务器耗时 1 min，启动耗时 30s 左右
- 又因为特殊的网络环境，只能由特定的一个人打包，传到 33 服务器，特定的一个人从 33 服务器把 jar 包拷贝到 114 服务器并启动。这又会导致替包时长加 1-2 min
- 有些在 xxl-job 的调度任务里抛的异常在日志文件里不好找，需要到 xxl-job 里找

如果采用了 arthas，就能解决上述一些问题

- 解决**内网开发虚机慢**的问题：内网虚机里用 IDEA 启动调试项目能查到更多信息，但是内网开发虚机卡。而且内网虚机解决不了环境问题，比如本地没有 xxl-job，服务器上的 xxl-job 需要特别指定本机才行。方法需要用本地
- 定位问题慢的问题：arthas 可以直接调用指定的方法。在由确定的入参和期望的方法返回值时，可以用此功能验证方法是否有问题。缺点是调用方法可能会修改数据库的数据状态，事后可能需要手动改回去
- 打包替包耗时问题：arthas 提供了用新的 .java / .class 
- 特殊网络环境问题：如果只需要修改一两个类里的代码，替换 .java 文件的传输速度要比打包快很多


使用建议（乍现的想法）

- 如果用新  .java 文件替掉线上的 .class 文件，最好加上一条 log 输出用于验证运行的是不是提上去的新文件。log 内容可以是【类名 + 递增版本号】，递增版本号用来干这个的，可能需要多次替换，版本号用于log出时验证提上去/正在运行的是新版的 .java 不是旧版的 .class


11.24 号，发现114 服务器上，升级项目后，升级内容包含 APP 引擎相关功能，但是 APP 引擎的每 30s 执行一次的 xxl-job 任务调度方法没有被创建，最终花近 1 小时找问题，1 小时验证

找问题流程

1. 从发现bug的傅译了解到 APP 引擎调度任务的定时任务创建失败
2. 去 info 日志里查询，发现报错，是 JSONUtil.paraObj 把对象转 json 报的错（用 vi + 全局搜索 ’APP‘ 相关关键字），方法的参数是 HttpUtil.post 的返回值
3. 尝试复现问题，在本地单元测试调用 JSONUtil.paraObj，传入 null，结果没报错并把 null 转为 `{}`，没有定位到问题
4. 去 error 日志里查看，发现 error 日志有 32 G，用 vi 打开很费时间，打开后搜索到的报错和上面类似，但其上面还有 xxl-job 工具类的报错，猜测 XxlJobUtil.login 报错导致下面的调用都失败了
5. 百度 XxlJobUtil.login 和 XxlJobUtil.addJob 调的接口，发现这些接口都是 XXL-JOB admin Web UI 上前端调的接口。如果没有调 login 接口就调其他接口，会得到登录页的 html 数据。本地自测，不调 login 就调其他接口，发现接口返回空字符串。空字符串作为参数传入 JSONUtil.paraObj 时的错和线上一样。基本可以确定是 login 失败了
6. 我推测 login 失败是因为网络不稳定导致请求失败，后来傅译怀疑配置文件里的密码和 114 上的 xxl-job 密码不一样，经验证，是一样的
7. 经过傅译的疑问，我推测配置文件里的密码是错误的，两个人意见不一致的原因是我认为配置文件用的是 cdos_base 下的文件，傅译和王少宇认为是 jxw 目录下的。经过 30 分钟的讨论和验证，用的确实是 cdos_base 下的文件，而这个文件里的 xxl-job 密码是错误的。得出结论，java -jar 执行 jar 文件时用的外部配置文件是执行指令时所在目录下的配置文件，而不是 jar 包同级目录下的配置文件

- arthas 能不能读取 Springboot 用的配置文件的地址？如果能，将减少验证时间
- 此外，如果 arthas 能查询方法之前的执行结果（arthas 接入之前时方法的调用结果）那将能直接看到创建 APP 调度任务失败的原因
- 如果能单独替换线上的 class 文件，在添加调用 login 前打印得到的密码日志这个验证过程所需时间也会减少




https://www.yuque.com/arthas-idea-plugin


https://github.com/qunarcorp/bistoury



# 案例


## 查询数据有误

http://172.16.3.100/issues/22899

查询历史任务的【负责人】字段有误

实际结果



期望结果



admin 账号登录后，查询结果是正常的，jhl 账号登录上去后，查询结果就是【2222222222222222222】

限制条件：测试环境不能替包，并且这个问题只有测试环境里有，开发环境没能复现问题

定位代码：定位到【责任人】字段是调用 `UserCache.getUser(taskHistory.getCreateUser()).getName()` 方法获取到的。理论上来看，admin和 jhl 的入参和返回值应该是一样的。但从前端页面上来看，jkl取到的返回值显然不对

如果用 arthas，就能实现在不替包的情况下 watch 方法的入参和返回结果


因为`UserCache.getUser(taskHistory.getCreateUser()).getName()`可能会从 redis 里取数据，所以有必要看看

但还没有看 redis 里的数据对不对，理由如下

- 如果入参一样，~~admin 和 jhl 访问的应该是 redis 里同一个 key~~
- redis 里保存的对象是 protobuf 序列化过的，redis 可视化工具看不了（也不一定，another redis deskmanager 有 protobuf 的反序列化功能）
- 测试环境 114 连不上 22 和 6379

后又经过思考，得出一个可能的原因，`UserCache.getUser(taskHistory.getCreateUser()) 会查 redis` 但程序对 redis 的配置是沿用态感和 bladeX的，也就是是租户隔离的

结论：admin 和 jhl 查 redis 被租户隔离了。可能有人登录 admin 后修改了 admin 的名字，但是接口只会更新 admin 租户在 redis 里的数据

