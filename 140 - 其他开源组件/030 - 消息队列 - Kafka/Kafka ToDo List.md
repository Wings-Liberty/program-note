## 偏移量

Kafka的logs目录中存在许多__consumer_offsets-xx

这是偏移量



偏移量类似于数组中的下标，又类似于指针

每次添加消息时向last指向的偏移量中添加数据，指针指向下一个数据

每次消费消息时。。。



每个kafka的broker的日志目录中都有很多偏移量文件





## 分区

每个主题的分区都有一个目录  目录名为主题名+分区序号  例如 “first-0”



分区的目录下有

- xxxxxxxx.log  存放消息数据
- xxxxxxxxxx.index   存放索引



## 数据的存储



数据存放在分区的目录中

例如：“first-0”

目录下有

- xxxxxxxx.log  存放消息数据  只有数据。数据连id号都没有
- xxxxxxxxxx.index   存放索引   索引包含id 和id对应的数据所在的偏移量，偏移量用于直接定位到log文件中数据的位置

默认.log文件大小达到1G后创建新的偏移量，创建新的.log和.index文件

ps：log文件和index文件的命名为所用偏移量范围中的最小偏移量，例如000010.log和000010.index使用的偏移量范围时10~100

一个log文件和一个index文件的组合是数据的一个片段（segment）单位





## 数据不丢失

数据不丢失由ack去保证

## 数据可靠性/一致性

数据的可靠性是对消费者而言的。**保证的是消费者的一致性** 不能保证数据不丢失

在kafka集群中由于从机的延迟。从机的还没将主机的新数据复制过来，主从的数据不一致

主机由 300条消息，从机有290条。但是消费者最多只能访问到第290条消息。这样做是为了防止主机挂掉，结果无法从新主机上获取到第290+后的消息。这种机制保证了数据的可靠性/一致性

数据的不丢失和数据的可靠性/一致性的区别就在于此



## offect

offect是由组，主题，分区组成。体现在一个topic中，主题名为consumer_offect





## 将部分数据存在zookeeper还是kafka中?

这个好像是通过命令控制的





## Follower 故障

而 kafka 非正常下线会导致 kafka 没有即时通知 zk


当分区的 leader 挂掉后由 broker 中的 leader 决定让 isr 中第一个存活的 follower 分区作为 leader 顶上


消费者能看见的最大偏移量是 HW（ack=-1?）

如果看不懂 pdf，就重新看视频，因为视频的 ppt 会动（32）


## Leader 故障

leader 挂机，follower 顶上后会让其他 follower 抛弃比自己多出来的部分，这会导致消息丢失。但 kafka 要求数据一致性 > 数据丢失（33-34）


![[../../91 - 静态资源/Pasted image 20220713094204.png]]

L：leader
F：follower

创建 16个分区 3 个副本时，第一轮 第一个 F 跟在 L 后

第二轮 第一个 F 会和 L 隔一个 broker

以此类推


36

低配机器上的  leader 宕机后，高配机器上的 follower 会变成 leader，即时低配机器重启，也只能当 follower 了

长时间会导致 leader  都聚集在高配机器上，导致高配机访问量过大

频繁触发自动平衡会导致 kafka 频繁进行 leader 选举，浪费性能

（图中所示分区分布是已经出现过 leader 宕机 follower 顶上的行为了，因为 leader 和 replied 中第一个 broker id 不同）



## 文件存储机制
38

.timeindex 可以被用于 kafka 删除过期数据时查询消息日期

顺序写，所以不能修改数据（因为修改数据不能确定新数据的长度，所以不能改）


![[../../91 - 静态资源/Pasted image 20220713095939.png]]

**稀疏索引**是个新名词

39

思考题答案：因为删除 segment 的依据是 segment 中最大时间戳，所以因为最大时间戳还没有过期，所以即使部分过期也不会删除 segment


日志压缩不是真压缩，而是把以追加方式实现的数据修改中那些被修改后的，无用的数据删掉

压缩用的比较少



## 消费者消费方式

42

一个消费者可以消费多个分区的数据，但每个分区只能被一个消费者消费（一对多的关系）

所以，消费者消费是完全独立的


一个分区只能被一个消费组里的一个消费者消费，但如果是不同消费组里的消费者就能同时消费同一个分区


消费者消费到哪了，偏移量被保存在 kafka 的主题里（老版本把消费者偏移量存在 zk 里）

44

消费组里的消费者根据 groupid 计算出一个 分区号，然后所有消费者都找这个分区里的coordinator 询问自己应该消费哪个分区

对 50 求模，50 是 consumer offset 的分区数

消费者初始化的第 7 步很重要（面试题高频）

45

![[../../91 - 静态资源/Pasted image 20220713122434.png]]

这两个配合使用。如果kafka 新数据没有到 fetch.min.bytes 消费者也不会非等数据到达指定大小后才获取，当超过 fetch.max.wait.ms 后还没获取过数据也会主动获取


46

kafka 消费者收到消息后不用发送 ack？

49

消费者组中有消费者宕机，默认 45s 内 kafka 不会再平衡，等 45s 后进行平衡后，原宕机消费者负责的分区中的数据才会被分配到其他消费者

（重新平衡后，原本应被宕机消费者消费却没被消费的消息会被消费，所以不会出现消息丢失）

53

offset 自动提交相当于消费者对消息的自动确认。kafka 只能按时间间隔自动提交

所以会存在消息丢失问题吗？消费者没消费完消息就宕机，但 kafka 已经确认完消息了

55

示例代码中

手动指定 offset 时需要指定分区号，分区号可用消费者 api 获取

但消费者初始化时间较长，所以立即调用 api 可能获取到的分区原数据是空的，因此调用获取分区元数据时用 while 非空判断


示例代码让重启消费者时修改消费者组 id，因为上次消费后会修改消费者组对分区的 offset（即确认了消息消费偏移量？？有人说上节讲错了）

56

根据偏移量把偏移量转为时间

57

自动提交 offset 引起重复消费。消费了消息但还没提交 offset。消费者宕机。消费者重启后按照旧 offset 重新消费消息，出现消息重复消费

也可能消息 offset 被提交，但消息没消费完消费者就宕机，造成消息丢失


事务 + 手动提交解决重复消费和漏消费，同时还要保证下游服务器也有事务

但目前还没有学过怎么用事务解决这两个问题

58

加分区，加消费者，修改一次性获取数据的数量减少通信开销



65-70

跳过 kfaft，flume 和 spark


75-96

跳过调优和源码浅析