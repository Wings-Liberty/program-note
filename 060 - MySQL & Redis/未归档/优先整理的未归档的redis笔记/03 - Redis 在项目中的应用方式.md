
# Redis 在项目中的应用方式

Redis 是数据库，不要刻板地认为它只能做缓存

还能做主数据库，能保存那些系统长期运行时的统计计算结果



## Redis 构建应用程序

目标：用更快的 redis 查询来代替传统的关系型数据库查询，以及完成一些关系型数据库无法高效完成的任务



### 文章投票功能

项目背景：文章投票，文章评分，按评分展示 top n



功能 A 要求：

- 能投票，取消投票，不能投反对票
- 评分 ≈ 投票数 + 文章发布时间（文章发的越早这部分的加分就越少 = 随着时间的流逝，只有高投票数才能得到高评高分）
- 把有趣的文章放在文章列表最前列至少一天（有趣的文章 = 一天之内得到 200 票的文章）

假设和目标：每天发布 1000 篇，有 50 篇有趣的文章，把这 50 篇文章放在列表前 100 位至少一天



实现方式：

- hash 结构保存文章。每个 hash 保存一篇文章
- zset 实现 articleId => score，实现文章分数记录和按分数排序
- set 实现投票记录，记录用户是否对某篇文章投过票



> - 上述的评分计算公式，保证了评分值在文章发布后只随投票数量变化而变化。如果公式为 评分 = 投票数 - 文章存在时间 就麻烦了。因为理论上当投票数不变时评分也会随着时间推移而变化。
> - 用 redis 保存对象时，key 的命名风格为 “功能名:类名:ID号”



功能 B 要求：

- 每篇文章都属于若干个群组（多对多）
- 能快速获取文章属于哪个群组
- 能快速获取某个群组内有哪些文章



实现方式：

- set 实现群组里都有哪些文章，key 为 groupName，val 为 articleId
- hash 实现的文章存储中，添加一个 field 保存 groupName



> - set 提供检查某个元素是否在集合内的行为。还提供了多个集合间的集合运算，以及和有序集合的计算。所以有时 set 是一个很好的工具
> - 集合提供的 XXXstore 命令还能把集合运算结果存入新 key 中并设置过期时间，这个 key 中的值能被作为缓存，下次再进行相同的计算时直接返回结果



### 用户访问权限信息缓存

cookie 实现用户认证时，有两种方式：签名 cookie，令牌 cookie

- 签名 cookie：还有用户不敏感信息的字符串再加上一段数字签名。数字签名用于检查令牌完整性以及是否被篡改过
- 令牌 cookie：乱序字符串。包含了权限信息，用于后端校验用户的访问权限



JWT 是一种签名实现的令牌，可根据实际情况，被放在 url 后，请求头里，或请求体中

签名型的令牌一旦被签发，其失效时间就是固定的

要求实现功能：实现用户主动登出后让令牌失效



要求实现的功能：实现用户主动登出后令 JWT 失效的功能



实现方式：

- set 保存所有被要求主动失效的令牌
- 或用很多 string 保存所有主动失效的令牌

如果用的是 set， 那集合中可能会有很多元素，为防止失效令牌过多，应该先清楚已经失效的令牌，再清除马上就失效的令牌，这需要清理线程完成。且必须用 zset，因为 zset 有排序功能

如果用的是 string，虽然能为每个 key 设置过期时间，但如果 key 过多，需要主动删除一些 key，string 不能做到清除马上就失效的 key。只能等内存用尽时 redis server 主动采用失效策略删除 key



所以用 zset 实现更好



### 数据缓存

之前实现的功能基本都是用 redis 保存并计算程序运行时的一些统计信息，程序用这些信息实现业务功能



要求实现的功能：设计出合适的数据结构保存数据缓存



当 redis 作为数据缓存时，读多写少，常用于缓存数据行，可用 json 实现

- key (String) 为 "项目名:数据库名:表名:主键值"，val 为 json 格式的一个数据行的数据
- 或 key (String 或 List) 为 "项目名:接口名:参数"，val 为 json 格式的若干个数据行的数据



这些作为缓存的 key 同样需要设置过期时间



## Redis 实现数据统计功能



### 网页分析 - 统计数据访问频率

数据库中数据有很多，不可能把所有数据都放缓存里。因此需要分析哪些数据需要被缓存



要求实现的功能：分析数据被访问的频率，得出哪些数据有被缓存的价值



分析：

这个需求时文章投票功能的变种。数据浏览量 = 文章投票数

数据被访问的越频繁就越有缓存价值。被高频访问的数据就类似 “有趣的文章”



实现方式：

- zset 保存数据唯一标识符和浏览量。根据浏览量排序
- 为防止 zset 过大。用清理线程优先淘汰浏览量少的数据



这个需求的实现类似用 redis 实现 LRU



### 日志归档 - 归档统计数据

记录日志的常用方案是，不断把日志写入一个日志文件，每过一段时间后就创建一个新的日志文件并向新的日志文件写日志。



要求实现：用 redis 实现上述的日志写和日志归档功能



实现方式：

- 用编程语言控制 redis 客户端实现流程控制、
- 当前日志均写入 redis 的 cur list
- 当到达创建新日志文件的时间点时，把 cur list 更名为 old list。并把数据写入新的 list 里
- 用 watch 机制方式防止多个客户端同时执行上述的日志归档行为



> 仅当被归档的数据还会被频繁访问时才会用 redis 实现归档，否则归档数据应该被持久化，而不是已知驻留在 redis 的内存里



### 计数器实现

在统计一些数据访问指标时，可能要求统计某段时间内的数据访问频率。程序根据访问频率进行一些技术层面的缓存，或修改销售层面的销售策略



要求实现的功能 A：用 redis 实现同时运行多种精度的计数器



分析：

比如，获取数据 a 在近期时间内，每 1s ，5s ，1min ，5min ，1h 内的被访问次数

要求数据结构能快速访问某个商品在某段时间内的被访问次数



即时间戳为 key ，val 为这个时间段内所有数据被访问的次数。key 为 zset，数据标识符为 member，访问量为 score

或商品标识符为 key，val 为这个商品在某段时间内的被访问次数。key 为 zset，时间戳为 member，访问量为 score

但通常不会要求对同一个数据在不同时间内的访问量进行排序，所以用 hash 保存也行



实现方式：

- 一个 hash 保存一个数据在一种精度下的所有时间段的被访问量

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220521161303854.png" alt="image-20220521161303854" style="zoom:80%;" />

如上图，表示某个数据在 timestamp ~ timestamp + 5s 时间段内的被访问次数

- key 是时间段的起始时间时间戳
- val 是这个时间段内被访问的次数

 归档方式和上一个 ”日志归档“ 功能相同



要求实现的功能 B：清除计数器中过早的访问量统计数据



分析：获取的所有的计数器，删除过早的访问量统计数据



实现方式：hash 实现，key 为计数器名，每次添加 1 个新时间戳时，都尝试删除 1 个旧时间戳





因为每个数据都有一个计数器，所以为了知道有哪些计数器，还需要用一个 zset 保存计数器名

> 用 zset 而不是 list 或 set，是因为要求每次遍历计数器的顺序都是固定的，set 做不到；不能包含重复元素，list 做不到。所以用 zset，为了保证顺序固定，把 member 的 score 都设为 0
>
> 不过也不一定必须用 zset，如果能保证计数器名不重复，用 list 能节省空间。而且计数器名通常不会重复



### 长时间的数据聚合统计

某个资源被访问的次数是需要被统计的数据，但这不是全部。被访问的资源还有很多有价值的数据需要被统计

所以上述的计数器仅仅是 redis 实现数据统计的一小部分



Q：什么场景下才需要用 redis 实现数据统计功能？

A：当从到统计这些数据的行为非常费时，且结果数据量很少时



如果统计数据中一个 key 需要保存不止一项数据，仿照 “网页分析” 方式使用合适的数据结构保存数据

如果统计数据需要根据时间进行归档保存，仿照 “日志归档” 进行归档工作

如果统计数据需要收集不同时间精度的数据，仿照 “计数器” 方式进行分精度统计



> 保存统计数据时，要灵活使用 set 和 zset
>
> - 和 list 相比，集合不能高效进行入队和出队，但把分值设为统一值的 zset 能和 list 一样有序遍历元素
> - 和 hash 相比，集合也能保证唯一性，且能排序，能进行集合运算。**集合的数学运算有时能很方便地处理数据**



需要实现的功能 A：统计所有页面在不同时间段内的访问时间上下文



实现方式：

- 为每个页面设置一个 key，保存平均加载时间，访问次数，最长加载时间，最短加载时间，标准差等



> key 的数据类型可以是 hash 也可以是 zset。根据实际情况
>
> - 用 zset 就能进行集合运算和排序
> - 用 hash 能实现快速查找和更新 field



需要实现的功能 B：根据页面被访问的时间和频率，为需要被缓存的页面进行缓存



分析：查询加载时间长的页面，然后缓存它们。为了获取加载时长 top n 的元素，需要排序

如果功能 A 用的 key 是 zset 类型的，就很方便排序了



## Redis 构建应用程序组件



### 分布式互斥锁

以实现一个分布式锁的基本步骤和会遇到的问题为主线，渐进式实现一个分布式锁，并为锁添加新功能已解决问题



分布式锁和本地锁的主要区别在于

- 竞争本地锁的对象是一个进程里的多个线程
- 竞争分布式锁的对象是分布式系统中的多个网络进程

以下是一个分布式锁需要具有的功能

- 基本功能：阻塞式加锁，解锁
- 防止锁持有者宕机：为锁添加超时时间
- 防止锁的有效期过短，锁在持有者未宕机时自动失效：如果持锁进程还活着，就续签锁超时时间
- 防止锁的有效期过长，而锁持有者需要锁的时间过短：锁的超时时间和续签时间由客户端决定，而不是写死的
- 防止 redis 集群下多个客户端向多个未执行同步的从库获取同一个锁：加锁后，强制执行一次主从同步



> 通常加锁行为都是阻塞式的，因为无超时时间的非阻塞式加锁基本和乐观锁差不多了。因为它们都需要加锁失败时进行重试



redis 实现的分布式锁是悲观锁，redis 提供的 watch 机制是乐观锁。如果数据并发修改程度高，那么 watch 会导致大量的重试，性能不如悲观锁

尤其是多个事务都在修改 watch key 时，重试概率大大提升，事务内的多条多次失效，导致性能降低



锁实现

- 加锁：`SETNX` key val。把 UUID 设为 val，防止其他进程获取或释放🔒。伪代码如下

```java
public String acquire_lock (int timeout) {
    while (cur < timeout) { // 未到超时时间就继续抢锁
        if(redis.setnx("lock", uuid)){
            return uuid; // 获取锁成功就返回
        }
    } // 获取锁失败就重新抢
    return null;
}
```

- 解锁：用 UUID 对比已经存在的🔒的 value，如果一样，说明本进程就是🔒持有者，有权删除🔒。获取锁和删除锁的行为必须是原子的，在此用乐观锁实现锁的释放

```java
public boolean release_lock (String lockName, String uuid) {
    while (true) {
        redis.watch(lockName);
        redis.multi();
        if ( redis.get(lockName) == uuid ) {
            redis.del(lockName);
            redis.exce();
        }
        redis.unwatch();
    }
}
```

- 带有超时限制的锁：这个行为被期望上锁和设置超时时间是原子操作
  - redis 2.6 后 set 指令添加了设置过期时间的可选项，可实现上述原子操作
  - redis 2.6 前使用上锁时用 set 和 expire 命令，如果上锁失败，检查锁是否存在过期时间，如果没有就设置一个（防止客户端执行 set 和 expire 时宕机导致锁没有过期时间）



目前锁的释放只能用 watch 乐观锁或 lua 脚本实现原子性，因为 redis 没有提供一次性执行获取 key 和删除 key 的原子命令



### 分布式信号量

基本功能：多个进程抢占或释放信号量。获取信号量失败时直接返回，不阻塞

容灾：

- 被获取的信号量应该有过期时间
- 保证进程没有宕机或重大错误的情况下能一直持有锁



上节实现的分布式锁是非公平锁，这次实现公平的信号量

上次用 expire 实现锁的释放，这次可以用有序数组实现（zset）



v1.0：用 zset 保存信号量的持有者信息

- member 是 uuid，用于 zrem 释放信号量
- score 是抢占信号量请求的起始时间时间戳



v2.0：为防止多客户端时间戳不统一问题，信号量持有者的起始时间戳应该由 redis server 统一决定

> redis 能用 time 指令获取当前时间戳

所以用累加器表示持有者获取信号量的顺序，再用保存客户端时间戳的方式进行信号量的释放。





刷新或者说续签信号量持有时间的方式为：直接向 zset 添加成员，因为集合的唯一性，zadd 也有更新数据的含义

但如果 zadd 的是新数据，而不是更新行为，那么这是条非法的续签行为，因为续签仅限于已被持有的信号量



# 构建社交网站



1. 构建一个简单的搜索引擎
2. 用搜索引擎实现一个简单的广告定向引擎



## 关键字搜索功能介绍

> 通常搜索功能应该用像 ES 这样的工具。这里用 Redis 实现搜索是为了加深对 Redis 的理解



用关键字搜索数据行时，进行逐行扫描的效率很低下。所以各大搜索引擎采用反向索引实现关键字搜索



- **正向索引**用于用散列性较强的字段检索数据行

比如，用 id 在 B+Tree 中查询节点



- **反向索引**用于根据关键字定位到符合条件的多条数据

比如，用关键词查询包含 key 的所有文章



反向索引可以用这样的数据结构

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220610184958878.png" alt="image-20220610184958878" style="zoom: 50%;" />

上图表示，docA，docB 文件中包含关键字 **lord**；docA 文件中包含关键字 **rings**



> 为了减少内存消耗，提高查询效率，就不保存那些频繁出现却不表示有用信息或实际意义的词，比如：of，and，is，are，I，we 等单词



## 关键字搜索功能实现



### 用反向索引实现查询

根据 key 获取到 key 的 set，set 保存了含有 key 的文件

这个查询效率是非常高的



```java
entries = search(key);
```



### 构建反向索引

添加一篇新文章时，需要提取出文章中的词，并提取出可能称为搜索关键字的词。把这些词放到反向索引中就算完成了反向索引的构建



```java
words = tokenize(doc); // 提取词汇
words = filter.doFilter(words); // 过滤不能作为搜索关键字的词
buildReverseIdx(words, docName); // 构建反向索引
```



### 修改反向索引

当删除文章或修改文章内容时，通常需要修改反向索引



如果文章添加了新词，就调用 `buildReverseIdx(newWords, docName);` 创建索引

如果文章删除了旧词，且这些词在文章中的出现次数归零，就从 word 的 set 中移除掉本文章



### 复杂搜索

**同义词搜索**

例子：如果希望用 “目录” 和 “文件夹” 作为关键字时，得到的搜索结果是相同的，那么就需要构建同义词搜索



**过滤搜索**

例子：希望搜索不包含 “大数据技术” 的文章



**多关键字搜索**



复杂搜索可以**用集合运算实现**，比如

- 用并集计算获取 key 及其同义词的所有反向索引 set
- 用差集计算不包含某些 key 的所有反向索引
- 用交集计算同时包含 key1，key2 的反向索引



### 关联度排序搜索结果

用 sort 并指定合适的排序属性，对搜索结果进行简单的关联度排序



但 sort 只能根据一个属性进行排序。如果要用多个属性进行综合排序，可以用有序集合的 score 实现。



如果排序字段不是数字型，可先把非数字型值转为数字后再作为 score 进行排序



## 广告定向引擎功能介绍

广告定向引擎用于收集用户个人信息和行为信息后，分析这些数据再向用户投放其可能感兴趣的广告

- 用户个人数据包括：姓名，年龄，性别，地理位置
- 用户的行为信息包括：对某些链接的点击次数，对某些站点的访问次数，经常浏览的页面中包含的文字或词汇

根据以上行为分析出用户可能感兴趣词汇，根据这些词汇和权重从广告库中搜索匹配程度较高的广告

但通常一次广告搜索只返回一个搜索结果，而不是一组搜索结果



以上行为就是广告定向引擎的行为。很明显，广告搜索行为可以用搜索功能实现



### 把新广告插入索引

1. 提取出广告的元数据（目标用户的年龄，性别，地理位置等）
2. 提取出广告中的关键词
3. 把元数据和关键词放到反向索引中
4. 把广告的关键词保存起来（为之后的用户行为学习做准备）



### 用索引检索广告

根据用户的个人信息和行为信息查询一条广告，当使用用户浏览页面中的单词作为查询条件时，需要为每个单词设置匹配分值



在查询出多条匹配的广告后，选择匹配分值最高的一条作为结果返回



所以需要**为每个单词设置在每篇文章中的权重**或者**为每个用户设置每个单词的权重**



### 学习用户行为



对于不同的用户来说，同一些单词的权重是不同的。因此需要根据用户的浏览记录学习用户的行为，调整单词的权重。这样在计算匹配到的广告的分值时，就更容易把用户可能感兴趣的广告置顶



用户的行为可以来自于

- 用户搜索时常用的关键词
- 用户浏览的页面中的关键词
- 曾经被定向给定广告的单词



