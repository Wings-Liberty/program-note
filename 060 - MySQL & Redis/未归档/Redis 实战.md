#还没有复习 

> 本书用的 redis 主要围绕着 redis2.6 前后的特性进行描述的



# 第一部分：基本介绍和核心概念



## 简介

- 用途：Redis 可用作主存储和二级存储（缓存，或计算和保存系统运行时数据）
- 存储单元：提供存储键（key）和 5 种不同类型的值（value）之间的映射（mapping）
- 复制：主从复制，读写分离，扩展读性能
- 客户端分片：扩展写性能，可获得线性级别的性能提升（分片策略如： ID 分段，散列值，组合 key）
- 支持聚合函数：比如 incr



## Redis 五大数据结构

五大数据结构包括：`String`, `List`, `Hash`, `Set`, `ZSet`（有序集合）



五大数据结构有些通用的命令，比如：`del`, `type`, `rename`



- **对 value 为空的 key 进行操作**：redis 中对一个不存在的 key 自增或覆盖其值时会自动创建 key 并令其零值为默认值，再执行覆盖或自增
- **key 的 value 为空时**：如果一个 key 没有 value，这个 key 会被自动删除。比如 list 里的元素都被取出，list 这个 key 就会被自动删除
- **尝试获取一个 value 为空的 key**：如果获取（包括但不仅限于 GET，LPOP）一个不存在的 key 会返回 null（如果 key 是 String）或空（什么都没有，但不是 null）
- **区间查询时的区间定义**：redis 中使用的范围查询多为闭区间，且 0 表示第一个元素的下标，-1 表示最后一个元素的下标
- **不支持嵌套结构**：比如 hash 中有多个 kv，v 只能是 String，不能是 String 以外的数据类型
- **通用指令格式**：`instruct [opts] keys [values]`



如果有需要，比如需要保存复杂的对象，可以用 hash 或 json 字符串保存具有层级结构的对象



### 字符串 - String

> 值可以是字符串，整数，浮点数。实际类型由 redis 自行判断

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220512155702675.png" alt="image-20220512155702675" style="zoom:67%;" />

**基础命令**：`get`, `set`, `del`

**进阶命令 - 数字自增和自减命令**：`incr`, `decr`, `incrby`, `decrby`, `incrbyfloat`

**进阶命令 - 处理字符串子串和二进制位命令**：`append`, `getrange`, `setrange`, `getbit`, `setbit`, `bitcount`, `bitop`



### 列表 - List

> 链表表上每个节点都包含一个 String 作为 value

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220512160112567.png" alt="image-20220512160112567" style="zoom:67%;" />

**基础命令**：`rpush`, `lpush`, `rpop`, `lpop`, `lrange`, `lindex`, `ltrim`

**进阶命令 - 阻塞式弹出和在列表间移动元素命令**：`blpop`, `brpop`, `rpoplpush`, `brpoplpush`



### 集合 - Set

> 集合支持交集，并集，差集计算

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220512161420082.png" alt="image-20220512161420082" style="zoom:67%;" />

**基础命令**：`sadd`, `srem`, `smembers`, `sismember`, `srandmember`, `spop`, `smove`

**进阶命令 - 集合运算**：`sdiff`, `sdiffstore`, `sinter`, `sinterstore`, `sunion`, `sunionstore`



### 散列 - Hash

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220512162212002.png" alt="image-20220512162212002" style="zoom:67%;" />

**基础命令**：`hset`, `hget`, `hgetall`, `hdel`, `hlen`

**进阶命令**：`hexists`, `hkeys`, `hvals`, `hincrby`, `hincrbyfloat`



### 有序集合 - ZSet

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220512163241778.png" alt="image-20220512163241778" style="zoom:67%;" />

**基础命令**：`zadd`, `zrem`, `zcard`, `zrange`, `zrangebyscore`, `zincrby`, `zcount`, `zrank`, `zscore`

 **进阶命令 - 范围获取和范围删除命令，集合运算命令**：`zrevrank`, `zrevrange`, `zrangebyscore`, `zrevrangebyscore`, `zremrangebyrank`, `zremrangebyscore`, `zinterstore`, `zunionstore`



- ZREV* 命令中，元素都是基于从大到小排列后再进行计算的
- 有序集合的集合计算命令中有两个可选参数
  - AGGREGATE SUM | MIN | MAX。表示计算时遇到多个相同元素时，进入集合的元素的分值取值。可选项均是聚合函数
  - WEIGHTS weight [weight..]。当命令中有集合（普通集合 set）时，可用 weight 指定每个集合中所有元素的分值。如果不指定，默认集合中的所有元素的分值均为 1



## 排序

sort 命令可以对所有 keys 排序，命令需要指定参与排序的 key，比较大小用的 val，排序用什么字典序，升序还是降序



```bash
SORT source-key [By pattern] [LIMIT offset count] [Get pattern [Get pattern ...]] [ASC|DESC] [ALPHA] [STORE dest-key]
```



具体使用方式参考[这里](https://redis.io/commands/sort/)



## 事务

事务相关的指令

- `MULTI` 开始事务
- `WATCH` 监听  key（key 可以不存在）
- `UNWATCH` 取消监听 key
- `DISCARD` 放弃事务
- `EXEC` 执行事务



介绍：Redis 的事务并不支持 ACID，因为它不保证原子性。事务内的多个命令各自执行各自的，一条命令的失败或出现的异常也会继续执行下一条命令



- `MULTI`的工作原理：当 Redis 从一个客户端那里接收到`MULTI`时，Redis 会将这个客户端之后发送的所有命令都放入到一个队列里面，直到这个客户端发送`EXEC`命令后 Redis 就会在不被打断的情况下，一个接一个地执行存储在队列里面的命令



**WATCH**

- `WATCH`的生命周期：`WATCH`命令只能用在发送`MULTI`命令前，在调用`EXEC`指令执行结束后失效（即取消监控所有的 3key）
- 工作原理：先监听 key，再开启事务。如果当前会话监听的 key 被其他会话修改了，那么执行事务时就会放弃执行事务队列里的所有命令，结束所有监听，并返回`nil`



watch 就是 redis 实现的乐观锁实现。如果事务执行失败就尝试重试，直到能被执行



> 因为事务中的指令会被 redis 服务端的单线程一次性地连续，所以不用担心在事务执行时 redis server 又插入执行了一条其他会话要求修改被监听 key 值的命令。即事务要么能被执行（虽然有些命令可能会出现异常），要么一条都不执行（因为监听的 key 的值被其他会话修改了）



## 简单的性能测试和性能提升



**批量传送指令**

用 redis 客户端批量发送命令，而不是需要执行一条就发送一条。这样能减少网络传输次数

很多 redis 客户端都为事务提供伪批量执行。在客户端调用`exce`后才把队列中的指令一次性发给 redis。这些客户端通常也会为非事务指令提供批量发送的 api



**简单的性能测试**

`redis-benchmark`命令的运行结果会展示一些常用的命令在 1s 内可以执行的次数



**使用多个 “数据库”**

一个 redis server 默认有 16 个数据库。把数据分摊到 16 个数据库里也能有效提高执行效率



## 键的过期时间和键的清理工作

键的过期时间的设置命令如下

| 命令      | 描述                                                 |
| --------- | ---------------------------------------------------- |
| EXPIRE    | 让给定键在指定的秒数之后过期                         |
| PERSIST   | 移除键的过期时间                                     |
| TTL       | 查看给定键距离过期还有多少秒                         |
| EXPIREAT  | 将给定键的过期时间设置为给定的 UNX 时间戳            |
| PTTL      | 查看给定键距离过期时间还有多少毫秒                   |
| PEXPIRE   | 让给定键在指定的毫秒数之后过期                       |
| PEXPIREAT | 将一个毫秒级精度的 UNIX 时间戳设置为给定键的过期时间 |

键过期后会被自动删除

但`expire`的缺点是，它只能作用于一整个 key，而不能作用于一个 key 中的部分数据。比如`expire`不能作用于一个 hash 的某些 field，只能作用于整个 hash key



redis 删除键的方式有 3 种

- 溢出删除：内存不够放进新键时，redis 会用键的淘汰策略，删除一部分 key 为新 key 腾空间
- 过期删除：键过期后进行即时删除或懒删除
- 手动删除：用户自行编写清理线程，手动清理



## 数据安全和性能保障



### 数据持久化

两种持久化方案：rdb 快照，aop 只读追加文件



持久化的目的：重用数据，数据备份，数据迁移和容灾恢复。保存那些程序长时间，并计算过大量数据后才统计出来的结果



#### RDB 快照

如果不知道快照是什么，可以看看这篇文章 [快照是什么？揭秘存储快照的实现](https://cloud.tencent.com/developer/article/1158686)



redis 通过`SAVE`和`BGSAVE`命令创建快照

- `SAVE`。执行此命令时，在创建快照完毕之前不在响应任何其他命令。不常用，通常在内存不够或能容忍持久化期间不执行其他指令时才会用
- `BGSAE`。执行此命令时，调用 fork 创建子进程，子进程负责把快照写入磁盘，父进程继续工作。fork 会创建进程的副本，副本和父进程共享内存，所以`BGSAVE`费内存，但不影响 redis 继续响应其他指令。但`BGSAVE`在创建子进程的过程中也会引起系统的卡顿

> 如果数据量过大，`BGSAVE`创建子进程 + 创建快照将会比较耗时，创建子进程也会引起系统卡顿，所以可以考虑关掉自动保存，用手动保存方式控制卡顿时机发生在 redis 压力不大的时候

执行创建快照命令的时机

- 客户端主动发送`SAVE`或`BGSAE`指令
- 调用`SHUTDOWN`命令关机或收到 OS 的标准`TERM`信号时调用`SAVE`创建快照
- 满足配置文件中的 save 选项时调用`BGSAE`命令创建快照（save 选项的推荐配置为默认配置）
- 从机请求复制主机数据时调用`BGSAE`（从机向主机发送`SYNC`命令）



rdb 快照会把快照数据都放在 .rdb 文件里

如果宕机，用户将丢失最近一次生成快照后更改的数据



#### AOF 只读追加文件

追加可以发生在每次执行命令后，每秒追加一次或交给系统决定何时执行追加



- `appendonly yes`表示开启 aof 功能
- `appendsync`选项指定文件同步时机

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220512204905475.png" alt="image-20220512204905475" style="zoom: 67%;" />

推荐每秒同步一次，其对性能几乎没有影响



为防止 .aof 文件膨胀，redis 会在合适的时机执行`BGREWRITEAOF`命令，对文件进行压缩

- 配置`auto-aof-rewrite-min-size`指定 .aof 文件大小必须超过阈值后才能考虑执行重写
- 配置`auto-aof-rewrite-percentage`指定 .aof 文件大小比上次重写后体积大多少比例时就执行重写

```
auto-aof-rewrite-min-size 64m // aof 文件超过 64M 后考虑重写
auto-aof-rewrite-percentage 100 // aof 文件比上次重写后的大小大一倍时重写，推荐值设置为 100 以上
```



文件压缩方式主要包括：合并冗余命令，去掉冗余命令



`BGREWRITEAOF`命令的工作原理和`BGSAVE`类似，需要 fork 创建子进程，所以也存在性能问题和内存占用问题



#### 两种方式的优缺点

保存相同的数据量时。rdb 文件小，执行恢复时间短。aof 文件大，执行恢复时间长



### 复制

复制用于主从复制，读写分离。提高 redis 集群的读性能



尤其是进行费时的命令时，redis 采用单线程模型执行指令，耗时指令将阻塞其他还未被执行的指令

搭建主从架构后，整个集群的读行为相当于无锁的多线程读



复制的整体流程为：从机发送`SYNC`命令请求主机的快照文件，**从机自动清空自身数据**，并根据快照文件全量复制。复制完毕后，开始持续接收并执行主机发送的逻辑指令以实现复制目的



开启 redis 的主从复制不需要太多的配置，复制相关的配置在于 redis 服务器是如何变成主机和从机的

只需要`SLAVEOF `一个指令

- `SLAVEOF NO ONE`命令用于终止复制
- `SLAVEOF host port`命令让服务器作为从机，开始向目标主机复制

`SALVEOF`可以直接在客户端执行，也可以在配置文件里配置

> 较新版本的 redis 用的命令是`REPLICAOF`，`SLAVEOF`是旧版本 redis 用的命令，但两个命令的参数都一样（貌似是因为 slave 带有歧视含义，所以被弃用了）

<center>从机连接主机时的详细复制步骤</center>

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220513215332821.png" alt="image-20220513215332821" style="zoom:67%;" />



和多数能搭建主从复制的数据库一样，redis 也**不支持主主复制**；如果从机过多，为减少主机分发增量复制用的逻辑指令，可以**搭建中间层**，即主机下有少量的一级从机，一级从机有各自的二级从机

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220513221130629.png" alt="image-20220513221130629" style="zoom:80%;" />

生产环境下不一定非要这么做，但这种树形结构是可行，合理的



### 应用层检查数据落盘情况

aof 和 rdb 实现了数据持久化，新增数据会在合适时机被写入磁盘

如果程序要求必须立刻验证数据是否被写入磁盘，而不仅限于数据是否已经在 redis 的内存中，需要应用层实现

调用`INFO`命令查看`aof_pending_bio_fsync`属性是否为 0，如果是，表示所有已知的数据都保存到了磁盘里



> `INFO`命令提供了大量和 redis 服务器当前状态相关的信息，这对于了解 redis 服务器的综合状态很有帮助



### 故障处理

用 aof 和 rdb 持久化数据，文件可用于数据恢复。搭建主从架构时，从机的持久化文件也起到备份作用



redis 遇到数据损坏，需要恢复数据时，需验证 rdb 和 aof 文件的完整性。更换出现故障的主机或重启从机



- `redis-check-aof`和`redis-check-rdb`用于检查和修复 aof 文件和 rdb 文件
  - 修复 aof 文件时，直接删除第一个不完整或错误的命令及其后面的所有命令（简单粗暴）
  - rdb 文件不能被修复，因为快照文件本省经过压缩，所以不能对压缩后的文件进行修复。文件的完整性校验通过校验和和散列值完成
- 主机出现故障时
  - 让一台新的 redis 主机用从机的快照文件恢复数据，再让从机开始复制这台主机
  - 或让数据完整性最好的从机作为主机，再让新的 redis 机器作为从机跟上主机（哨兵模式下能实现自动的故障转移）



# 第二部分：Redis 在项目中的应用方式

Redis 是数据库，不要刻板地认为它只能做缓存

还能做主数据库，能保存那些系统长期运行时的统计计算结果



## Redis 构建应用程序

目标：用更快的 redis 查询来代替传统的关系型数据库查询，以及完成一些关系型数据库无法高效完成的任务



### 文章投票功能

项目背景：文章投票，文章评分，按评分展示 top n



功能 A 要求：

- 能投票，取消投票，不能投反对票
- 评分 ≈ 投票数 + 文章发布时间（文章发的越早这部分的加分就越少 = 随着时间的流逝，只有高投票数才能得到高评高分）
- 把有趣的文章放在文章列表最前列至少一天（有趣的文章 = 一天之内得到 200 票的文章）

假设和目标：每天发布 1000 篇，有 50 篇有趣的文章，把这 50 篇文章放在列表前 100 位至少一天



实现方式：

- hash 结构保存文章。每个 hash 保存一篇文章
- zset 实现 articleId => score，实现文章分数记录和按分数排序
- set 实现投票记录，记录用户是否对某篇文章投过票



> - 上述的评分计算公式，保证了评分值在文章发布后只随投票数量变化而变化。如果公式为 评分 = 投票数 - 文章存在时间 就麻烦了。因为理论上当投票数不变时评分也会随着时间推移而变化。
> - 用 redis 保存对象时，key 的命名风格为 “功能名:类名:ID号”



功能 B 要求：

- 每篇文章都属于若干个群组（多对多）
- 能快速获取文章属于哪个群组
- 能快速获取某个群组内有哪些文章



实现方式：

- set 实现群组里都有哪些文章，key 为 groupName，val 为 articleId
- hash 实现的文章存储中，添加一个 field 保存 groupName



> - set 提供检查某个元素是否在集合内的行为。还提供了多个集合间的集合运算，以及和有序集合的计算。所以有时 set 是一个很好的工具
> - 集合提供的 XXXstore 命令还能把集合运算结果存入新 key 中并设置过期时间，这个 key 中的值能被作为缓存，下次再进行相同的计算时直接返回结果



### 用户访问权限信息缓存

cookie 实现用户认证时，有两种方式：签名 cookie，令牌 cookie

- 签名 cookie：还有用户不敏感信息的字符串再加上一段数字签名。数字签名用于检查令牌完整性以及是否被篡改过
- 令牌 cookie：乱序字符串。包含了权限信息，用于后端校验用户的访问权限



JWT 是一种签名实现的令牌，可根据实际情况，被放在 url 后，请求头里，或请求体中

签名型的令牌一旦被签发，其失效时间就是固定的

要求实现功能：实现用户主动登出后让令牌失效



要求实现的功能：实现用户主动登出后令 JWT 失效的功能



实现方式：

- set 保存所有被要求主动失效的令牌
- 或用很多 string 保存所有主动失效的令牌

如果用的是 set， 那集合中可能会有很多元素，为防止失效令牌过多，应该先清楚已经失效的令牌，再清除马上就失效的令牌，这需要清理线程完成。且必须用 zset，因为 zset 有排序功能

如果用的是 string，虽然能为每个 key 设置过期时间，但如果 key 过多，需要主动删除一些 key，string 不能做到清除马上就失效的 key。只能等内存用尽时 redis server 主动采用失效策略删除 key



所以用 zset 实现更好



### 数据缓存

之前实现的功能基本都是用 redis 保存并计算程序运行时的一些统计信息，程序用这些信息实现业务功能



要求实现的功能：设计出合适的数据结构保存数据缓存



当 redis 作为数据缓存时，读多写少，常用于缓存数据行，可用 json 实现

- key (String) 为 "项目名:数据库名:表名:主键值"，val 为 json 格式的一个数据行的数据
- 或 key (String 或 List) 为 "项目名:接口名:参数"，val 为 json 格式的若干个数据行的数据



这些作为缓存的 key 同样需要设置过期时间



## Redis 实现数据统计功能



### 网页分析 - 统计数据访问频率

数据库中数据有很多，不可能把所有数据都放缓存里。因此需要分析哪些数据需要被缓存



要求实现的功能：分析数据被访问的频率，得出哪些数据有被缓存的价值



分析：

这个需求时文章投票功能的变种。数据浏览量 = 文章投票数

数据被访问的越频繁就越有缓存价值。被高频访问的数据就类似 “有趣的文章”



实现方式：

- zset 保存数据唯一标识符和浏览量。根据浏览量排序
- 为防止 zset 过大。用清理线程优先淘汰浏览量少的数据



这个需求的实现类似用 redis 实现 LRU



### 日志归档 - 归档统计数据

记录日志的常用方案是，不断把日志写入一个日志文件，每过一段时间后就创建一个新的日志文件并向新的日志文件写日志。



要求实现：用 redis 实现上述的日志写和日志归档功能



实现方式：

- 用编程语言控制 redis 客户端实现流程控制、
- 当前日志均写入 redis 的 cur list
- 当到达创建新日志文件的时间点时，把 cur list 更名为 old list。并把数据写入新的 list 里
- 用 watch 机制方式防止多个客户端同时执行上述的日志归档行为



> 仅当被归档的数据还会被频繁访问时才会用 redis 实现归档，否则归档数据应该被持久化，而不是已知驻留在 redis 的内存里



### 计数器实现

在统计一些数据访问指标时，可能要求统计某段时间内的数据访问频率。程序根据访问频率进行一些技术层面的缓存，或修改销售层面的销售策略



要求实现的功能 A：用 redis 实现同时运行多种精度的计数器



分析：

比如，获取数据 a 在近期时间内，每 1s ，5s ，1min ，5min ，1h 内的被访问次数

要求数据结构能快速访问某个商品在某段时间内的被访问次数



即时间戳为 key ，val 为这个时间段内所有数据被访问的次数。key 为 zset，数据标识符为 member，访问量为 score

或商品标识符为 key，val 为这个商品在某段时间内的被访问次数。key 为 zset，时间戳为 member，访问量为 score

但通常不会要求对同一个数据在不同时间内的访问量进行排序，所以用 hash 保存也行



实现方式：

- 一个 hash 保存一个数据在一种精度下的所有时间段的被访问量

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220521161303854.png" alt="image-20220521161303854" style="zoom:80%;" />

如上图，表示某个数据在 timestamp ~ timestamp + 5s 时间段内的被访问次数

- key 是时间段的起始时间时间戳
- val 是这个时间段内被访问的次数

 归档方式和上一个 ”日志归档“ 功能相同



要求实现的功能 B：清除计数器中过早的访问量统计数据



分析：获取的所有的计数器，删除过早的访问量统计数据



实现方式：hash 实现，key 为计数器名，每次添加 1 个新时间戳时，都尝试删除 1 个旧时间戳





因为每个数据都有一个计数器，所以为了知道有哪些计数器，还需要用一个 zset 保存计数器名

> 用 zset 而不是 list 或 set，是因为要求每次遍历计数器的顺序都是固定的，set 做不到；不能包含重复元素，list 做不到。所以用 zset，为了保证顺序固定，把 member 的 score 都设为 0
>
> 不过也不一定必须用 zset，如果能保证计数器名不重复，用 list 能节省空间。而且计数器名通常不会重复



### 长时间的数据聚合统计

某个资源被访问的次数是需要被统计的数据，但这不是全部。被访问的资源还有很多有价值的数据需要被统计

所以上述的计数器仅仅是 redis 实现数据统计的一小部分



Q：什么场景下才需要用 redis 实现数据统计功能？

A：当从到统计这些数据的行为非常费时，且结果数据量很少时



如果统计数据中一个 key 需要保存不止一项数据，仿照 “网页分析” 方式使用合适的数据结构保存数据

如果统计数据需要根据时间进行归档保存，仿照 “日志归档” 进行归档工作

如果统计数据需要收集不同时间精度的数据，仿照 “计数器” 方式进行分精度统计



> 保存统计数据时，要灵活使用 set 和 zset
>
> - 和 list 相比，集合不能高效进行入队和出队，但把分值设为统一值的 zset 能和 list 一样有序遍历元素
> - 和 hash 相比，集合也能保证唯一性，且能排序，能进行集合运算。**集合的数学运算有时能很方便地处理数据**



需要实现的功能 A：统计所有页面在不同时间段内的访问时间上下文



实现方式：

- 为每个页面设置一个 key，保存平均加载时间，访问次数，最长加载时间，最短加载时间，标准差等



> key 的数据类型可以是 hash 也可以是 zset。根据实际情况
>
> - 用 zset 就能进行集合运算和排序
> - 用 hash 能实现快速查找和更新 field



需要实现的功能 B：根据页面被访问的时间和频率，为需要被缓存的页面进行缓存



分析：查询加载时间长的页面，然后缓存它们。为了获取加载时长 top n 的元素，需要排序

如果功能 A 用的 key 是 zset 类型的，就很方便排序了



## Redis 构建应用程序组件



### 分布式互斥锁

以实现一个分布式锁的基本步骤和会遇到的问题为主线，渐进式实现一个分布式锁，并为锁添加新功能已解决问题



分布式锁和本地锁的主要区别在于

- 竞争本地锁的对象是一个进程里的多个线程
- 竞争分布式锁的对象是分布式系统中的多个网络进程

以下是一个分布式锁需要具有的功能

- 基本功能：阻塞式加锁，解锁
- 防止锁持有者宕机：为锁添加超时时间
- 防止锁的有效期过短，锁在持有者未宕机时自动失效：如果持锁进程还活着，就续签锁超时时间
- 防止锁的有效期过长，而锁持有者需要锁的时间过短：锁的超时时间和续签时间由客户端决定，而不是写死的
- 防止 redis 集群下多个客户端向多个未执行同步的从库获取同一个锁：加锁后，强制执行一次主从同步



> 通常加锁行为都是阻塞式的，因为无超时时间的非阻塞式加锁基本和乐观锁差不多了。因为它们都需要加锁失败时进行重试



redis 实现的分布式锁是悲观锁，redis 提供的 watch 机制是乐观锁。如果数据并发修改程度高，那么 watch 会导致大量的重试，性能不如悲观锁

尤其是多个事务都在修改 watch key 时，重试概率大大提升，事务内的多条多次失效，导致性能降低



锁实现

- 加锁：`SETNX` key val。把 UUID 设为 val，防止其他进程获取或释放🔒。伪代码如下

```java
public String acquire_lock (int timeout) {
    while (cur < timeout) { // 未到超时时间就继续抢锁
        if(redis.setnx("lock", uuid)){
            return uuid; // 获取锁成功就返回
        }
    } // 获取锁失败就重新抢
    return null;
}
```

- 解锁：用 UUID 对比已经存在的🔒的 value，如果一样，说明本进程就是🔒持有者，有权删除🔒。获取锁和删除锁的行为必须是原子的，在此用乐观锁实现锁的释放

```java
public boolean release_lock (String lockName, String uuid) {
    while (true) {
        redis.watch(lockName);
        redis.multi();
        if ( redis.get(lockName) == uuid ) {
            redis.del(lockName);
            redis.exce();
        }
        redis.unwatch();
    }
}
```

- 带有超时限制的锁：这个行为被期望上锁和设置超时时间是原子操作
  - redis 2.6 后 set 指令添加了设置过期时间的可选项，可实现上述原子操作
  - redis 2.6 前使用上锁时用 set 和 expire 命令，如果上锁失败，检查锁是否存在过期时间，如果没有就设置一个（防止客户端执行 set 和 expire 时宕机导致锁没有过期时间）



目前锁的释放只能用 watch 乐观锁或 lua 脚本实现原子性，因为 redis 没有提供一次性执行获取 key 和删除 key 的原子命令



### 分布式信号量

基本功能：多个进程抢占或释放信号量。获取信号量失败时直接返回，不阻塞

容灾：

- 被获取的信号量应该有过期时间
- 保证进程没有宕机或重大错误的情况下能一直持有锁



上节实现的分布式锁是非公平锁，这次实现公平的信号量

上次用 expire 实现锁的释放，这次可以用有序数组实现（zset）



v1.0：用 zset 保存信号量的持有者信息

- member 是 uuid，用于 zrem 释放信号量
- score 是抢占信号量请求的起始时间时间戳



v2.0：为防止多客户端时间戳不统一问题，信号量持有者的起始时间戳应该由 redis server 统一决定

> redis 能用 time 指令获取当前时间戳

所以用累加器表示持有者获取信号量的顺序，再用保存客户端时间戳的方式进行信号量的释放。





刷新或者说续签信号量持有时间的方式为：直接向 zset 添加成员，因为集合的唯一性，zadd 也有更新数据的含义

但如果 zadd 的是新数据，而不是更新行为，那么这是条非法的续签行为，因为续签仅限于已被持有的信号量



# 第三部分：提高 Redis 性能

通过使用短结构，位图保存数据减少占用的内存

通过使用单机分片，多机分片提高写性能；读写分离提高查效率



降低内存占用会带来很多好处：减少`.rdb`，`.aop`的写入时间，缩短主从同步时间，腾出更多的空间保存其他数据



## 短结构 - 压缩列表，整数集合和位图

短结构：存储长度较短的结构



在 list、hash、zset 的长度较短或体积较小时，使用压缩列表（ziplist）的紧凑型结构保存数据

当上述类型的 key 的长度或体积较大时就会使用经典的数据结构保存数据

- list 用双向链表
- hash 用散列表
- zset 用散列表和跳表

> redis3.2 添加了新的短结构：quicklist



### 压缩列表



压缩列表：内存连续，由多个表项组成，每个表项 = cur_len + value  + pre_len 

cur_len 表示本节点的 value 长度，用于从前到后的遍历

pre_len 表示上一个节点的长度，用于从后向前遍历

这种方式保存数据能节省空间。当 key 的长度或体积较小时会用紧凑结构，这个阈值可以在配置文件里配

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220527201237884.png" alt="image-20220527201237884" style="zoom: 80%;" />

上述选项表示 key 中存多少个 entity 且 entity 的大小不超过多少（单位是字节）时就用紧凑结构

如果不符合任意一项就会转紧凑型结构为经典结构，且转换不可逆



> 可以用`DEBUG OBJECT KEY`命令查看 key 对象的相关信息，这些会包含 key 的底层数据结构



### 整数集合

set 的紧凑型结构。当 set 的成员都能用十进制整数表示时，且整数处于本软硬件平台的有符号范围之内，set 的成员数量又比较少时就用整数集合



set 使用整数集合结构的阈值选项如下

```
set-max-intset-entities 512
```



当整数数量少时，set 的底层数据结构是`intset`，当数量变多后就用`hashtable`



### 紧凑型结构的缺点

当紧凑结构的体积变的太大后，操作这些结构的速度会变的越来越慢。以上两种紧凑结构的缺点都集中在

- 紧凑结构的内存分布是连续的，添加或删除数据后存在数据移动问题
- 紧凑结构没有索引，只能顺序遍历查询 key



### 单机分片

先单机分片的目的是

- 让一个 “大 key” 的多个 “分片 key” 都保存较少的数据，这样就能用到短结构，减少内存占用
- 提高查询速度和写入速度



注意事项：

- hash，set，zset 的单机分片好实现，list 的单机分片需要依靠 lua 脚本
- 实际场景下，用 zset 通常都会用到 score。如果用 hash 策略进行分片，那么分片的意义就不大，因为 hash 分片会把所有的 score 分散到各个分片里，hash 分片后所有依赖 score 的命令需要遍历所有的分片
- 单机的分片行为需要在代码上自行实现，跨机分片可以用中间件自动实现
- 如果要对键 X 进行单机分片，需要让操作 X 的所有指令都支持单机分片行为
- 分片策略有很多种（段号，哈希）



> 对键 X 的分片的命名常用：X:<shardid> 或 Y:<shardid>
> 或直接用 redis 提供的 16 个 db 实现分片（存在切换库的开销？）



hash 分片策略的缺点：hash 不一致性会导致如果分片的数量发生变化后需要进行数据迁移



> 分片的局限性：
>
> - 不管是单机分片还是跨机分片，一旦数据量达到一定程度就不再存在短结构省内存的优点
> - 很多用于聚合统计的数据不适合保存在分片中。比如计数器，常用计数器判断某些执行次数是否达到上限，如果把聚合统计数据分散到多个分片里，将很



### 其他建议

- 尽量让键名保持简短。键名包含 key，member，field 等需要用户起的名字
- 将字符串存到 hash 里。如果存在大量的 String 类型的 key，且 key 名多为 namespace:id，value 为短字符或数字。用 hash 能省内存（因为 value 很短，所以按百分比来算，key 名中的 namespace 占了很多空间）
- 当需要进行大量数据的唯一性判断时（比如判断某个标识符是否被标记过），用位图或布隆过滤器要比用集合好得多
  - 位图适用于连续的序列号的唯一性判断
  - 布隆过滤器适用于分散的字符串，且容许少数失败的唯一性判断
- 如果要根据数据量预先为 key 分配空间或分片数量，就进行数据统计。把统计结果给下一次分配空间或分片数量时做参考（如果有必要，还可以对这个统计结果进行上下取整，如 Java 的 HashMap 的容量总是 2 的 n 次幂）



### 位图

位图常用于以紧凑的格式保存计数器，定长字符串，布尔值等数据



比如，常用位图保存用户的在线状态，每一位的位置信息表示 uid，值信息表示用户是否在线（这里的 0、1 起布尔值的作用）



每个信息占用的内存越多，保存的信息就越详细



保存用户在线信息时，每个用户的信息仅占用了一位。如果每个数据占用 2 个字节，那么获取信息时，只需要注意正确地计算出数据偏移量的起始地址即可



> redis 用动态字符串实现 String ，按需为其分配内存，如果不够再扩容。redis 的位图完全由 String 实现
>
> 一个 字符串 key 最大为 512 MB。如果突然对对一个长度很短的字符串，进行 setbit，且 set 的偏移量很大，字符串就需要先完成扩容，这个行为可能很耗时



位图也可以进行分片设计，且因为字符串的访问无需任何编解码，能实现随机访问，所以位图的分片数量可以非常多

位图的 api 就是 String 提供的能操作位的命令



## 扩展读写性能



### 主从复制

因为主从复制会提高系统复杂性，且需要应对复制的开销

所以在开始搭建 Redis 主从架构前，应该保证已经做过以下行为

- 用过短结构
- 用过单机分片
- 对读多写少的大对象进行压缩后再保存
- redis 客户端使用流水线和连接池



主从复制会遇到的问题及其解决方案

Q：主机宕机

A：哨兵模式实现重新选举主机



Q：从机过多导致主机需要大量分发复制命令

A：搭建多层次的主从结构，主机的直接从机作为中间层，主机只发送少量复制命令给有限的中间层从机，中间层分发给大量的底层从机

缺点：提高了系统的复杂度，增加了处理故障的难度



Q：复制速度慢

A：使用带压缩的 SSH 隧道进行链接。压缩的开销不会非服务器造成很大的负担



### 哨兵模式

哨兵会监视主机和从机，识别其他哨兵

当主机失效后，哨兵集群选举出一个哨兵作为决策哨兵，决策哨兵选择一台从机作为新主机，提醒其他从机跟随新主机并开始复制



### 分片

再提高写性能前，先尝试一切办法降低内存占用，减少需要写入的数据量

- 从应用层设计角度，减少需要写入的数据
- 用短结构，用数据统计取代占用内存多的经典数据结构



如果单机优化到达瓶颈，就用跨机分片

一开始系统数据量少时，可先考虑在单机上运行多个 redis-server 实例进行分片行为。当数据量够大时再用多机搭建



在客户端用装饰器实现分片，根据参数获取分片连接。对于不能进行分片行为的 key 应用非分片方式获取非分片连接



# 第四部分：构建社交网站



1. 构建一个简单的搜索引擎
2. 用搜索引擎实现一个简单的广告定向引擎



## 关键字搜索功能介绍

> 通常搜索功能应该用像 ES 这样的工具。这里用 Redis 实现搜索是为了加深对 Redis 的理解



用关键字搜索数据行时，进行逐行扫描的效率很低下。所以各大搜索引擎采用反向索引实现关键字搜索



- **正向索引**用于用散列性较强的字段检索数据行

比如，用 id 在 B+Tree 中查询节点



- **反向索引**用于根据关键字定位到符合条件的多条数据

比如，用关键词查询包含 key 的所有文章



反向索引可以用这样的数据结构

<img src="https://wings-liberty.oss-cn-beijing.aliyuncs.com/note/image-20220610184958878.png" alt="image-20220610184958878" style="zoom: 50%;" />

上图表示，docA，docB 文件中包含关键字 **lord**；docA 文件中包含关键字 **rings**



> 为了减少内存消耗，提高查询效率，就不保存那些频繁出现却不表示有用信息或实际意义的词，比如：of，and，is，are，I，we 等单词



## 关键字搜索功能实现



### 用反向索引实现查询

根据 key 获取到 key 的 set，set 保存了含有 key 的文件

这个查询效率是非常高的



```java
entries = search(key);
```



### 构建反向索引

添加一篇新文章时，需要提取出文章中的词，并提取出可能称为搜索关键字的词。把这些词放到反向索引中就算完成了反向索引的构建



```java
words = tokenize(doc); // 提取词汇
words = filter.doFilter(words); // 过滤不能作为搜索关键字的词
buildReverseIdx(words, docName); // 构建反向索引
```



### 修改反向索引

当删除文章或修改文章内容时，通常需要修改反向索引



如果文章添加了新词，就调用 `buildReverseIdx(newWords, docName);` 创建索引

如果文章删除了旧词，且这些词在文章中的出现次数归零，就从 word 的 set 中移除掉本文章



### 复杂搜索

**同义词搜索**

例子：如果希望用 “目录” 和 “文件夹” 作为关键字时，得到的搜索结果是相同的，那么就需要构建同义词搜索



**过滤搜索**

例子：希望搜索不包含 “大数据技术” 的文章



**多关键字搜索**



复杂搜索可以**用集合运算实现**，比如

- 用并集计算获取 key 及其同义词的所有反向索引 set
- 用差集计算不包含某些 key 的所有反向索引
- 用交集计算同时包含 key1，key2 的反向索引



### 关联度排序搜索结果

用 sort 并指定合适的排序属性，对搜索结果进行简单的关联度排序



但 sort 只能根据一个属性进行排序。如果要用多个属性进行综合排序，可以用有序集合的 score 实现。



如果排序字段不是数字型，可先把非数字型值转为数字后再作为 score 进行排序



## 广告定向引擎功能介绍

广告定向引擎用于收集用户个人信息和行为信息后，分析这些数据再向用户投放其可能感兴趣的广告

- 用户个人数据包括：姓名，年龄，性别，地理位置
- 用户的行为信息包括：对某些链接的点击次数，对某些站点的访问次数，经常浏览的页面中包含的文字或词汇

根据以上行为分析出用户可能感兴趣词汇，根据这些词汇和权重从广告库中搜索匹配程度较高的广告

但通常一次广告搜索只返回一个搜索结果，而不是一组搜索结果



以上行为就是广告定向引擎的行为。很明显，广告搜索行为可以用搜索功能实现



### 把新广告插入索引

1. 提取出广告的元数据（目标用户的年龄，性别，地理位置等）
2. 提取出广告中的关键词
3. 把元数据和关键词放到反向索引中
4. 把广告的关键词保存起来（为之后的用户行为学习做准备）



### 用索引检索广告

根据用户的个人信息和行为信息查询一条广告，当使用用户浏览页面中的单词作为查询条件时，需要为每个单词设置匹配分值



在查询出多条匹配的广告后，选择匹配分值最高的一条作为结果返回



所以需要**为每个单词设置在每篇文章中的权重**或者**为每个用户设置每个单词的权重**



### 学习用户行为



对于不同的用户来说，同一些单词的权重是不同的。因此需要根据用户的浏览记录学习用户的行为，调整单词的权重。这样在计算匹配到的广告的分值时，就更容易把用户可能感兴趣的广告置顶



用户的行为可以来自于

- 用户搜索时常用的关键词
- 用户浏览的页面中的关键词
- 曾经被定向给定广告的单词



